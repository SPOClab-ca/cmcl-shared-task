{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERTa Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import torch\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import src.eval_metric\n",
    "import src.model\n",
    "import src.dataloader\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/training_data/train.csv\")\n",
    "valid_df = pd.read_csv(\"../data/training_data/valid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = src.model.RobertaRegressionModel().to(device)\n",
    "train_data = src.dataloader.EyeTrackingCSV(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(12345)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in range(3):\n",
    "  for X_tokens, X_ids, X_attns, Y_true in train_loader:\n",
    "    optim.zero_grad()\n",
    "    X_ids = X_ids.to(device)\n",
    "    X_attns = X_attns.to(device)\n",
    "    predict_mask = torch.sum(Y_true, axis=2) >= 0\n",
    "    Y_pred = model(X_ids, X_attns, predict_mask).cpu()\n",
    "    loss = torch.sum((Y_true - Y_pred)**2)\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = src.dataloader.EyeTrackingCSV(valid_df)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=16)\n",
    "\n",
    "predict_df = valid_df.copy()\n",
    "predict_df[['nFix', 'FFD', 'GPT', 'TRT', 'fixProp']] = 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume one-to-one matching between nonzero predictions and\n",
    "predictions = []\n",
    "for X_tokens, X_ids, X_attns, Y_true in valid_loader:\n",
    "  X_ids = X_ids.to(device)\n",
    "  X_attns = X_attns.to(device)\n",
    "  predict_mask = torch.sum(Y_true, axis=2) >= 0\n",
    "  with torch.no_grad():\n",
    "    Y_pred = model(X_ids, X_attns, predict_mask).cpu()\n",
    "  \n",
    "  for batch_ix in range(X_ids.shape[0]):\n",
    "    for row_ix in range(X_ids.shape[1]):\n",
    "      if Y_pred[batch_ix, row_ix].sum() >= 0:\n",
    "        predictions.append(Y_pred[batch_ix, row_ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df[['nFix', 'FFD', 'GPT', 'TRT', 'fixProp']] = np.vstack(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for nFix: 10.774431877007759\n",
      "MAE for FFD: 1.272303595740354\n",
      "MAE for GPT: 3.703319213452447\n",
      "MAE for TRT: 3.2229711822020723\n",
      "MAE for fixProp: 53.34805603192507\n",
      "Overall MAE: 14.46421638006554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14.46421638006554"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.eval_metric.evaluate(predict_df, valid_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
